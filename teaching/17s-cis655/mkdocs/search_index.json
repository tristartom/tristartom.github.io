{
    "docs": [
        {
            "location": "/", 
            "text": "CIS655/CSE661: Advanced Computer Architecture\n\n\nInstructor: Yuzhe (Richard) Tang\n\n\nTextbook\n\n\n\n\nComputer Architecture: A Quantitative Approach, 5th Edition, The Morgan Kaufmann Series in Computer Architecture and Design\n\n\n(Recommended) Operating Systems: Principles and Practice, Second Edition\n\n\n(Recommended) CSAPP, Computer systems from programming perspective\n\n\n\n\nLectures\n\n\n\n\nOverview \n\n\nintro \n\n\nmetrics \n\n\n\n\n\n\nCPU \n\n\nILP \n pipelining \n\n\ndata hazard by compiler \n\n\nbranch hazard by HW \n\n\nmulti-issue \n SIMD \n\n\n(data hazard by HW, a. k. a tomasulo)\n\n\n\n\n\n\nMemory \n\n\ncache \n\n\ncache2 \n\n\nmemory \n\n\nmemory protection \n\n\n\n\n\n\nMulti-processing \n\n\nmultiprocessing \n\n\ncache-coherence \n\n\nsynchronization \n\n\nmemory consistency \n\n\nmany-core \n\n\n\n\n\n\nIO \n\n\nstorage \n\n\nraid \n lsm \n\n\ninterconnect \n\n\n\n\n\n\nWSC \n\n\nwsc \n\n\nenergy", 
            "title": "Home"
        }, 
        {
            "location": "/#cis655cse661-advanced-computer-architecture", 
            "text": "Instructor: Yuzhe (Richard) Tang", 
            "title": "CIS655/CSE661: Advanced Computer Architecture"
        }, 
        {
            "location": "/#textbook", 
            "text": "Computer Architecture: A Quantitative Approach, 5th Edition, The Morgan Kaufmann Series in Computer Architecture and Design  (Recommended) Operating Systems: Principles and Practice, Second Edition  (Recommended) CSAPP, Computer systems from programming perspective", 
            "title": "Textbook"
        }, 
        {
            "location": "/#lectures", 
            "text": "Overview   intro   metrics     CPU   ILP   pipelining   data hazard by compiler   branch hazard by HW   multi-issue   SIMD   (data hazard by HW, a. k. a tomasulo)    Memory   cache   cache2   memory   memory protection     Multi-processing   multiprocessing   cache-coherence   synchronization   memory consistency   many-core     IO   storage   raid   lsm   interconnect     WSC   wsc   energy", 
            "title": "Lectures"
        }, 
        {
            "location": "/hw/cachemiss/", 
            "text": "Programming Homework\n\n\nThe homework is to optimize computer program for matrix computations in terms of cache miss rate.\n\n\nA.Simple matrix traversal [30 points]\n\n\nA.1 Set up the system\n\n\n1.Copy the following code to a file \na11.cpp\n\n\n#include\niostream\n\n\nusing namespace std;\n\nint string2int(const string \n cppString){\n    const char* cstring = cppString.c_str();\n    int i = atoi(cstring);\n    return i;\n}\n\nint main(int argc, char *argv[]){\n    if(argc != 1 + 1){ //non argument case: argc = 1\n        cerr \n \nformat: ./a.out datasize\n \n endl;\n        cerr \n \nexample: ./a.out 1000\n \n endl;\n        return 0;\n    }\n\n    cout \n \nfirst commandline argument is \n \n argv[1] \n endl;\n\n\n    long datasize = string2int(argv[1]);\n    int * array = new int[datasize*datasize];\n\n    for (long i = 0; i \n datasize; i++){\n      for (long j = 0; j \n datasize; j++){\n        array[j*datasize+i] = i;\n      }\n    }\n\n    delete[] array;\n}\n\n\n\n\n2.Compile \na11.cpp\n using the following command.\n\n\ng++ -std=c++0x -O0  a11.cpp -o a11.out\n\n\n\n\n3.Run \na11.cpp\n by\n\n\n./a11.out 1000\n\n\n\n\n4.Measure the performance, and capture the cache miss rate. Specifically, we need to capture the miss rate of \nD1\n, that is, the L1 data cache. \n\n\nWhile you can use your favorable profiler to do cache profiling, I recommend to use Valgrind [\nCachegrind\n]. \n\n\nI have set up Valgrind on a VirtualBox image which can be downloaded from Blackboard.\n\n\nYou should set up VirtualBox by downloading it from Oracle website [\nlink\n]; You should choose installation file based on your local OS. Once you install VirtualBox successfully, you can download the image and launch an Ubuntu instance. On Ubuntu, you can find \na11.cpp\n on \n/programming/cachemiss/\n, and compile it to \na11.out\n. Then follow the instructions below to run the program while measuring \nD1\n miss rate.\n\n\ncd /programming/cachemiss/\n./tt_sh/profilerun_cache.sh ./a11.out 10000\n\n\n\n\nAfter running the command, you should be able to see something similar to the screen-shot below, from which you can find the \nD1\n miss rate (e.g. \n10.4%\n in the following screen-shot). Make note of the miss rate on your machine.\n\n\n\n\nA.2 Optimize the program\n\n\nOptimize the program by applying the idea of \"Loop Interchange\" as discussed in the class meeting. Save the optimized program to \na10.cpp\n and repeat the same process (for compiling, execution, and measurement).\n\n\nA.3 Deliverable\n\n\nYou should make a zip file containing:\n\n\n\n\nThe cache miss rate of running \na11.out\n on your system.\n\n\nYour optimized program (source code!): \na10.cpp\n.\n\n\nThe cache miss rate of running \na10.out\n on your system.\n\n\n\n\nAnd then submit the zip file to Blackboard.\n\n\nB. Matrix transpose [70 points]\n\n\nMatrix transpose is an operation that interchanges matrix rows and columns; the idea is illustrated in the pseudo code below:\n\n\nfor(i = 0; i \n 3; i++){\n    for(j = 0; j \n 3; j++){\n        output[j][i] = input[i][j];\n    }\n}\n\n\n\n\nB.1 Basic implementation\n\n\nThis part requires you to implement a program for matrix transpose. First provide a basic implementation based on code snippet above, run the program with a \n2000*2000\n matrix and measure the \nD1\n miss rate as described before. \n\n\nB.2 Optimization\n\n\nThen, optimize your implementation using the \"blocking\" idea discussed in the class. Re-run the program with a \n2000*2000\n matrix. \n\n\nVary the value of blocking factor and measure the cache miss rates accordingly. Report the relationship between the configured blocking factor and cache miss rate, and study the \"optimal\" value of blocking factor.\n\n\nB.3 Deliverable\n\n\nYou should make a zip file containing:\n\n\n\n\nYour basic implementation for matrix transpose (i.e. the compilable source code!).\n\n\nThe cache miss rate of running basic matrix-transpose program on your system.\n\n\nYour optimized program (i.e. the compilable source code!).\n\n\nThe cache miss rate of running optimized matrix-transpose program on your system. Here, you should include a series of (instead of just one) values for measured cache miss rates, under different setting of blocking factor. Report the optimal value of blocking factor that achieves the minimal miss rate.\n\n\nThe zip file from \nA.3\n\n\n\n\nAnd then submit the zip file to Blackboard.\n\n\n\n\n Yuzhe Tang, 2015", 
            "title": "cachemiss"
        }, 
        {
            "location": "/hw/cachemiss/#programming-homework", 
            "text": "The homework is to optimize computer program for matrix computations in terms of cache miss rate.", 
            "title": "Programming Homework"
        }, 
        {
            "location": "/hw/cachemiss/#asimple-matrix-traversal-30-points", 
            "text": "A.1 Set up the system  1.Copy the following code to a file  a11.cpp  #include iostream \n\nusing namespace std;\n\nint string2int(const string   cppString){\n    const char* cstring = cppString.c_str();\n    int i = atoi(cstring);\n    return i;\n}\n\nint main(int argc, char *argv[]){\n    if(argc != 1 + 1){ //non argument case: argc = 1\n        cerr    format: ./a.out datasize    endl;\n        cerr    example: ./a.out 1000    endl;\n        return 0;\n    }\n\n    cout    first commandline argument is     argv[1]   endl;\n\n\n    long datasize = string2int(argv[1]);\n    int * array = new int[datasize*datasize];\n\n    for (long i = 0; i   datasize; i++){\n      for (long j = 0; j   datasize; j++){\n        array[j*datasize+i] = i;\n      }\n    }\n\n    delete[] array;\n}  2.Compile  a11.cpp  using the following command.  g++ -std=c++0x -O0  a11.cpp -o a11.out  3.Run  a11.cpp  by  ./a11.out 1000  4.Measure the performance, and capture the cache miss rate. Specifically, we need to capture the miss rate of  D1 , that is, the L1 data cache.   While you can use your favorable profiler to do cache profiling, I recommend to use Valgrind [ Cachegrind ].   I have set up Valgrind on a VirtualBox image which can be downloaded from Blackboard.  You should set up VirtualBox by downloading it from Oracle website [ link ]; You should choose installation file based on your local OS. Once you install VirtualBox successfully, you can download the image and launch an Ubuntu instance. On Ubuntu, you can find  a11.cpp  on  /programming/cachemiss/ , and compile it to  a11.out . Then follow the instructions below to run the program while measuring  D1  miss rate.  cd /programming/cachemiss/\n./tt_sh/profilerun_cache.sh ./a11.out 10000  After running the command, you should be able to see something similar to the screen-shot below, from which you can find the  D1  miss rate (e.g.  10.4%  in the following screen-shot). Make note of the miss rate on your machine.   A.2 Optimize the program  Optimize the program by applying the idea of \"Loop Interchange\" as discussed in the class meeting. Save the optimized program to  a10.cpp  and repeat the same process (for compiling, execution, and measurement).  A.3 Deliverable  You should make a zip file containing:   The cache miss rate of running  a11.out  on your system.  Your optimized program (source code!):  a10.cpp .  The cache miss rate of running  a10.out  on your system.   And then submit the zip file to Blackboard.", 
            "title": "A.Simple matrix traversal [30 points]"
        }, 
        {
            "location": "/hw/cachemiss/#b-matrix-transpose-70-points", 
            "text": "Matrix transpose is an operation that interchanges matrix rows and columns; the idea is illustrated in the pseudo code below:  for(i = 0; i   3; i++){\n    for(j = 0; j   3; j++){\n        output[j][i] = input[i][j];\n    }\n}  B.1 Basic implementation  This part requires you to implement a program for matrix transpose. First provide a basic implementation based on code snippet above, run the program with a  2000*2000  matrix and measure the  D1  miss rate as described before.   B.2 Optimization  Then, optimize your implementation using the \"blocking\" idea discussed in the class. Re-run the program with a  2000*2000  matrix.   Vary the value of blocking factor and measure the cache miss rates accordingly. Report the relationship between the configured blocking factor and cache miss rate, and study the \"optimal\" value of blocking factor.  B.3 Deliverable  You should make a zip file containing:   Your basic implementation for matrix transpose (i.e. the compilable source code!).  The cache miss rate of running basic matrix-transpose program on your system.  Your optimized program (i.e. the compilable source code!).  The cache miss rate of running optimized matrix-transpose program on your system. Here, you should include a series of (instead of just one) values for measured cache miss rates, under different setting of blocking factor. Report the optimal value of blocking factor that achieves the minimal miss rate.  The zip file from  A.3   And then submit the zip file to Blackboard.    Yuzhe Tang, 2015", 
            "title": "B. Matrix transpose [70 points]"
        }
    ]
}